{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext, nltk   # NLP library\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "RAW_DATA_FOLDER = '../data/raw/'\n",
    "PROCESSED_DATA_FOLDER = '../data/processed/'\n",
    "DATASET = 'BeerAdvocate/'    # Can be either 'BeerAdvocate/' or 'RateBeer/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_pickle(PROCESSED_DATA_FOLDER + DATASET + 'reviews.pkl')\n",
    "beers = pd.read_pickle(PROCESSED_DATA_FOLDER + DATASET + 'beers.pkl')\n",
    "\n",
    "# Make sure there are no duplicates on the primary key\n",
    "reviews.drop_duplicates(subset=['beer_id', 'user_id', 'date'], inplace=True)\n",
    "beers.drop_duplicates(subset=['beer_id'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the adjectives that best describe each beer style?\n",
    "\n",
    "In order to help the consumers to choose a beer that would fit their tastes, we try to provide, for each main beer styles, a list of adjectives that best describe the style. \n",
    "\n",
    "To determine which adjectives best describe each style, we carry out a lexical analysis based on textual reviews. For a given beer style, the most informatives adjectives are those that occure the most in the textual reviews about the given beer style, but that does not occure to much in reviews of other beer style. To adjust for the fact that some adjectives appear more frequently in general (for example 'good' or 'bad'), we will use a TF-IDF approach, as it is one of the most popular term-weighting schemes today.\n",
    "\n",
    "This lexical analysis can be decomposed in the following steps:\n",
    "\n",
    "- Step 1: Group reviews by language.\n",
    "- Step 2: Group reviews by beer styles.\n",
    "- Step 3: Extract adjectives from the textual reviews.\n",
    "- Step 4: Compute the TF-IDF matrix where the documents are the list of adjectives for each beer styles\n",
    "- Step 5: Keep the adjectives with the greatest weight in the TF-IDF matrix for each beer styles.\n",
    "- Step 6: Visualize the selected adjectives per beer style."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Group reviews by language"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To group the reviews by language, a pre-trained language predictor provided by fastText library is used. If one wants to reproduce the following language classification, first make sure to have all the requirements (see requirements.txt in the root of the repository), then download the pre-trained language predictor [here](https://fasttext.cc/docs/en/language-identification.html) and place it in the `/src` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguagePredictor:\n",
    "\n",
    "    def __init__(self):\n",
    "        pretrained_lang_model = \"../src/lid.176.bin\"\n",
    "        self.model = fasttext.load_model(pretrained_lang_model)\n",
    "\n",
    "    def predict_lang(self, text):\n",
    "        predictions = self.model.predict(text)\n",
    "        language = re.sub(pattern='__label__', repl='', string=predictions[0][0])\n",
    "        score = predictions[1][0]\n",
    "        return language, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beer_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>score_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142544</td>\n",
       "      <td>nmann08.184925</td>\n",
       "      <td>2015-08-20 10:00:00</td>\n",
       "      <td>From a bottle, pours a piss yellow color with ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.891358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19590</td>\n",
       "      <td>stjamesgate.163714</td>\n",
       "      <td>2009-02-20 11:00:00</td>\n",
       "      <td>Pours pale copper with a thin head that quickl...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.924852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19590</td>\n",
       "      <td>mdagnew.19527</td>\n",
       "      <td>2006-03-13 11:00:00</td>\n",
       "      <td>500ml Bottle bought from The Vintage, Antrim.....</td>\n",
       "      <td>en</td>\n",
       "      <td>0.783006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19590</td>\n",
       "      <td>helloloser12345.10867</td>\n",
       "      <td>2004-12-01 11:00:00</td>\n",
       "      <td>Serving: 500ml brown bottlePour: Good head wit...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.852789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19590</td>\n",
       "      <td>cypressbob.3708</td>\n",
       "      <td>2004-08-30 10:00:00</td>\n",
       "      <td>500ml bottlePours with a light, slightly hazy ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.768192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beer_id                user_id                date  \\\n",
       "0   142544         nmann08.184925 2015-08-20 10:00:00   \n",
       "1    19590     stjamesgate.163714 2009-02-20 11:00:00   \n",
       "2    19590          mdagnew.19527 2006-03-13 11:00:00   \n",
       "3    19590  helloloser12345.10867 2004-12-01 11:00:00   \n",
       "4    19590        cypressbob.3708 2004-08-30 10:00:00   \n",
       "\n",
       "                                                text language  score_language  \n",
       "0  From a bottle, pours a piss yellow color with ...       en        0.891358  \n",
       "1  Pours pale copper with a thin head that quickl...       en        0.924852  \n",
       "2  500ml Bottle bought from The Vintage, Antrim.....       en        0.783006  \n",
       "3  Serving: 500ml brown bottlePour: Good head wit...       en        0.852789  \n",
       "4  500ml bottlePours with a light, slightly hazy ...       en        0.768192  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LanguagePredictor()\n",
    "reviews['language'] = reviews.text.apply(lambda x: model.predict_lang(x)[0])\n",
    "reviews['score_language'] = reviews.text.apply(lambda x: model.predict_lang(x)[1])\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en    2589044\n",
       "Name: Number of reviews, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_count = reviews.groupby('language').text.count().sort_values(ascending=False).rename('Number of reviews')\n",
    "language_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of reviews with language score bellow 0.9: 14.95%\n"
     ]
    }
   ],
   "source": [
    "nb_reviews = len(reviews)\n",
    "nb_reviews_low_lang_score = len(reviews[reviews.score_language < 0.9])\n",
    "\n",
    "print(\"Percentage of reviews with language score bellow 0.9: {:.2f}%\".format(100*nb_reviews_low_lang_score/nb_reviews))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the number of reviews in each language, the rest of the analysis will be done only on english reviews as there are not enough reviews for other language.\n",
    "\n",
    "Also, only reviews with a score language (confidence of the sentence belonging to the predicted language) greater or equal than 0.9 are considered. Doing so we throw away less than 15% of the reviews but we make sure to keep only reviews in the same language with high confidence and by the same time we discard dirty reviews (empty reviews, reviews with several languages ...etc..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = 'en'\n",
    "reviews = reviews[(reviews.language == LANGUAGE) & (reviews.score_language >= 0.9)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Group reviews by beer styles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to group the reviews by beer styles we first join the relations `beers` and `reviews` on `beer_id` key, we select `text` and `style` attributes and then we finally group the merged dataframe by `style`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = reviews.merge(beers, on='beer_id')[['text', 'style']]\n",
    "styles = merged['style'].unique()\n",
    "style_groups = merged.groupby('style')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Extract adjectives from the textual reviews"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the reviews of each beer style are tokenized using the tokenizer provided by `nltk` package. Then the Part-Of-Speech tagger from the same package is applied on each tokenized reviews. The adjectives are the token with the tag `JJ`. Adjectives used in reviews of the same beer style are then stored as a long string (`adjectives` variable) with space separator between adjectives. Since it takes a while to tag the tokens, the intermediate variable `adjectives` is stored in pickle files for each beer style. This allow the adjectives extraction to be done to be done iteratively, and only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for style in styles:\n",
    "    tokens = style_groups.get_group(style).text.apply(nltk.word_tokenize).tolist()\n",
    "    tagged_tokens = nltk.pos_tag_sents(tokens)\n",
    "    adjectives = ' '.join([word for (word, tag) in list(itertools.chain.from_iterable(tagged_tokens)) if tag == 'JJ'])\n",
    "    \n",
    "    with open(PROCESSED_DATA_FOLDER + 'adjectives/{}.pkl'.format(style)) as f:\n",
    "        pickle.dump(adjectives, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Compute the TF-IDF matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we aim at retrieving the adjectives that are the most informatives for each beer styles. \n",
    "\n",
    "As said before, for a given beer style, the most informatives adjectives are those that occure the most in the reviews, but we do not want the adjectives that frequently appear in every styles. To adjust for the fact that some adjectives appear more frequently in general (for example 'good' or 'bad'), we use a TF-IDF approach, as it is one of the most popular term-weighting schemes today. Here the terms are the adjectives and the documents are the adjectives belonging to the same beer style. \n",
    "\n",
    "From [WikiPedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf):\n",
    "The term frequency (tf) is the relative frequency of term t within document d and it is computed as follow:\n",
    "\n",
    "$$ \\operatorname{tf}(t, d)=\\frac{f_{t, d}}{\\sum_{t^{\\prime} \\in d} f_{t^{\\prime}, d}} $$\n",
    "\n",
    "where $f_{t, d}$ is the raw count of a term in a document, i.e., the number of times that term $t$ occurs in document $d$. Note the denominator is simply the total number of terms in document $d$ (counting each occurrence of the same term separately).\n",
    "\n",
    "One the other hand, the inverse document frequency (idf) is a measure of how much information the word provides, i.e., if it is common or rare across all documents, and it is computed ad follow:\n",
    "\n",
    "$$ \\qquad \\operatorname{idf}(t, D)=-\\log \\frac{n_t}{N} $$\n",
    "\n",
    "with\n",
    "- $N$ : total number of documents in the corpus $N=|D|$\n",
    "- $n_t$ : number of documents where the term $t$ appears (i.e., $\\operatorname{tf}(t, d) \\neq 0$ ). If the term is not in the corpus, this will lead to a division-by-zero. It is therefore common to adjust the numerator to $1+n_t$.\n",
    "\n",
    "Then tf-idf is calculated as\n",
    "$$\n",
    "\\operatorname{tfidf}(t, d, D)=\\operatorname{tf}(t, d) \\cdot \\operatorname{idf}(t, D)\n",
    "$$\n",
    "A high weight in tf-idf is reached by a high term frequency (in the given document) and a low document frequency of the term in the whole collection of documents; the weights hence tend to filter out common terms. Since the ratio inside the idf's log function is always greater than or equal to 1 , the value of idf (and tf-idf) is greater than or equal to 0 . As a term appears in more documents, the ratio inside the logarithm approaches 1 , bringing the idf and tf-idf closer to 0 .\n",
    "\n",
    "To compute the TF-IDF matrix, `TfidfVectorizer` from `Scikit-Learn` package is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for style in styles:\n",
    "    with open(PROCESSED_DATA_FOLDER + 'adjectives/{}.pkl'.format(style)) as f:\n",
    "        adjectives = pickle.load(f)\n",
    "    corpus.append(adjectives)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "TF_IDF = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Visualize the selected adjectives per beer style"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the selected adjectives per beer style a wordcloud is displayed where the size of each words is proportional to the tf-idf weight associated to the adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "TF_IDF = pd.DataFrame(TF_IDF.todense().tolist(), index=styles, columns=feature_names)\n",
    "\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=20).generate_from_frequencies(TF_IDF.iloc['American IPA'])\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ada_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88b2eb6153bd4aaf87bbf02d83ae32652ab637e467de3e2a5580d34d692db90e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
